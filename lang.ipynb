{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading audio from tatoeba\n",
    "# Clean CSV sentences/translations file\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(duplicates):\n",
    "    '''We don't want duplicate cards, so removes them with this function'''\n",
    "    clean_tags = list()              # Array that stores tags without duplicates\n",
    "    for tag in duplicates:           # Cycle through each tag\n",
    "        if tag not in clean_tags:    # If a duplicate is found, it is not added to new array\n",
    "            clean_tags.append(tag)   # Add unique tags to array\n",
    "    return clean_tags\n",
    "\n",
    "def remove_sentences(lines):\n",
    "    seen  = set()\n",
    "    block = [row for row in lines if row[0] not in seen and not seen.add(row[0])]\n",
    "    return block\n",
    "\n",
    "with open('Dutch tabbed.csv', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "tags = [lines[i][0] for i in range(len(lines))]                         # Get audio tag numbers from lines\n",
    "tags = remove_tags(tags)                                                # Call remove duplicates function\n",
    "\n",
    "# Populate a URL array where each URL contains a unique tag from the CSV file\n",
    "# Each URL links to a different MP3 file that corresponds to the sentences on the list\n",
    "urls = ['https://audio.tatoeba.org/sentences/nld/' + tags[i] + '.mp3' for i in range(len(tags))]\n",
    "\n",
    "for i in range(len(tags)):\n",
    "    r = requests.get(urls[i])\n",
    "    with open('/Users/Alexander/AppData/Roaming/Anki2/User 1/collection.media/' + tags[i] + '.mp3', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    #print(r.status_code)\n",
    "    #print(r.headers['content-type'])\n",
    "    #print(r.encoding)\n",
    "    \n",
    "print(' -- Download Done -- ')\n",
    "\n",
    "lines = remove_sentences(lines)                                 # Check for duplicate tags in lines\n",
    "\n",
    "for i in range(len(lines)): lines[i].pop(0)                     # Remove tags from first column in the CSV file\n",
    "\n",
    "for i in range(len(lines)): lines[i].append('[sound:' + tags[i] + '.mp3]')\n",
    "    \n",
    "with open('Dutch tabbed.csv', 'w', encoding='utf-8-sig') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines)\n",
    "    \n",
    "writeFile.close()\n",
    "\n",
    "print(' -- Finished -- ')\n",
    "\n",
    "## -- Roadmap --#\n",
    "#! open csv\n",
    "#! take first value of each row -> 'tag'\n",
    "#! check for duplicate tags\n",
    "#! remove duplicate tags\n",
    "#! use tag in url\n",
    "#! download audio to correct directory\n",
    "#! remove duplicate rows in csv\n",
    "#! delete tag value in csv\n",
    "#! add name of sound file using tag to end of each row in csv\n",
    "#! close readcsv\n",
    "#! close writecsv\n",
    "## ------------#\n",
    "\n",
    "# template:  url = 'https://audio.tatoeba.org/sentences/nld/378252.mp3'\n",
    "# media loc: C:\\Users\\Alexander\\AppData\\Roaming\\Anki2\\User 1\\collection.media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 2518\n",
      "from 1668 sentences\n",
      "------------\n",
      "other word count: 1416\n",
      "from 323 other sentences\n",
      "------------\n",
      "total word count: 3430\n",
      "from 1991 total sentences\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Count the number of Norwegian words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('Norwegian Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "#print(nor_set[0])\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('word count:', len(sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_words)): print(sorted_words[i][0], sorted_words[i][1])\n",
    "\n",
    "\n",
    "with open('My Norwegian Phrases.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines_other  = list(reader)                                               # Save contents as list 'lines'\n",
    "\n",
    "nor_set_other = [lines_other[i][0] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('other word count:', len(sorted_other_words))\n",
    "print('from', len(nor_set_other), 'other sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_other_words)): print(sorted_other_words[i][0], sorted_other_words[i][1])\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "print('total word count:', len(sorted_every_word))\n",
    "print('from', (len(nor_set) + len(nor_set_other)), 'total sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_every_word)): print(sorted_every_word[i][0], sorted_every_word[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of Chinese characters in Chinese learning Anki file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('SpoonFedChinese.txt', 'r', encoding = 'utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter = '\\t')\n",
    "    lines = list(reader)\n",
    "    \n",
    "readFile.close()\n",
    "\n",
    "cn_set = [lines[i][2] for i in range(len(lines))]\n",
    "\n",
    "all_char = {}\n",
    "\n",
    "for i in range(len(cn_set)):\n",
    "    \n",
    "    cn_set_spl = list(cn_set[i].replace(\" \", \"\").replace('-', '').replace(\".\", \"\"). replace(\"？\", \"\").replace(\"！\", \"\").replace(\"。\", \"\").replace(\"一\", \"\").replace(\"，\", \"\").replace(\"…\", \"\"))\n",
    "    \n",
    "    for j in range(len(cn_set_spl)):\n",
    "        if cn_set_spl[j] in all_char:\n",
    "            all_char[cn_set_spl[j]] = all_char[cn_set_spl[j]] + 1\n",
    "        else:\n",
    "            all_char[cn_set_spl[j]] = 1\n",
    "            \n",
    "sorted_char = sorted(all_char.items(), key = lambda x: x[1], reverse = True)\n",
    "print('Character count:', len(sorted_char))\n",
    "print('from', len(cn_set), \"sentences\")\n",
    "print('-------------------')\n",
    "for i in range(len(sorted_char)): print(sorted_char[i][0], sorted_char[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('ep1.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "n_lines = len(lines)\n",
    "\n",
    "try:\n",
    "    f = open('new_file.txt')\n",
    "except FileNotFoundError:\n",
    "    print('Creating new file')\n",
    "    with open('new_file.txt', 'a') as g:\n",
    "        g.close()\n",
    "finally:\n",
    "    f.close()\n",
    "\n",
    "# Add source tag to a new column\n",
    "with open('new_file.txt', 'w', encoding='utf-8-sig') as writefile:\n",
    "    for i in range(n_lines):\n",
    "        writefile.write('\\t'.join([lines[i][0], lines[i][1], 'NRK SKEK']) + '\\n')\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(n_lines)]\n",
    "\n",
    "nrk_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('/', '').replace(',', '').replace('-', '').replace('15', '').replace('50', '').replace('60', '').replace('400000', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in nrk_words:\n",
    "            nrk_words[nor_low_spl[j]] = nrk_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            nrk_words[nor_low_spl[j]] = 1\n",
    "\n",
    "nrk_sorted_words = sorted(nrk_words.items(), \n",
    "                      key=lambda x: x[1], \n",
    "                      reverse=True)\n",
    "\n",
    "print('Word Count:', len(nrk_sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "\n",
    "print('------------')\n",
    "\n",
    "#for i in range(len(nrk_sorted_words)):\n",
    "#    print(nrk_sorted_words[i][0], nrk_sorted_words[i][1])\n",
    "#if len(all_words) > len(nrk_words):\n",
    "#    for i in range(len(nrk_words)):\n",
    "#        if nrk_words\n",
    "    \n",
    "#else:\n",
    "if 'er' in nrk_words:\n",
    "    print(nrk_words.items())   \n",
    "\n",
    "#new_dict = all_words.union(nrk_words)\n",
    "#sorted_new = sorted(new_dict.items(),\n",
    "#                   key=lambda x: x[1],\n",
    "#                   reverse=True)\n",
    "\n",
    "#print(sorted_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "all_let = {}\n",
    "st = list(st.replace(\" \", \"\").lower().replace(\".\", \"\"))\n",
    "\n",
    "for i in range(len(st)):\n",
    "    if st[i] in all_let:\n",
    "        all_let[st[i]] = all_let[st[i]] + 1\n",
    "    else:\n",
    "        all_let[st[i]] = 1\n",
    "sort_let = sorted(all_let.items(), key = lambda x: x[1], reverse = True)\n",
    "print('Letter count: ', len(sort_let))\n",
    "print('from', len(st), 'letters')\n",
    "print('-------------')\n",
    "for i in range(len(sort_let)): print(sort_let[i][0], sort_let[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Download Complete -- \n"
     ]
    }
   ],
   "source": [
    "# From Futurelearn Frisian Course\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import csv\n",
    "\n",
    "url = 'https://ugc.futurelearn.com/uploads/assets/c7/ad/c7ad019c-918b-4cdb-be3a-b8be63ca9b32.mp3'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "with open('/Users/Alexander/Documents/College/Audio/Harmen.mp3', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "print(' -- Download Complete -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 1715\n",
      "from 1085 sentences\n",
      "------------\n",
      "other word count: 860\n",
      "from 521 other sentences\n",
      "------------\n",
      "total word count: 2099\n",
      "from 1606 total sentences\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Count the number of German words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('German Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "#print(nor_set[0])\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('word count:', len(sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_words)): print(sorted_words[i][0], sorted_words[i][1])\n",
    "\n",
    "\n",
    "with open('German Sentences.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines_other  = list(reader)                                               # Save contents as list 'lines'\n",
    "\n",
    "nor_set_other = [lines_other[i][0] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('other word count:', len(sorted_other_words))\n",
    "print('from', len(nor_set_other), 'other sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_other_words)): print(sorted_other_words[i][0], sorted_other_words[i][1])\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "print('total word count:', len(sorted_every_word))\n",
    "print('from', (len(nor_set) + len(nor_set_other)), 'total sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_every_word)): print(sorted_every_word[i][0], sorted_every_word[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Norwegian words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('Norwegian Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "nor_set = [lines[i][1] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "with open('My Norwegian Phrases.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines_other  = list(reader)\n",
    "\n",
    "nor_set_other = [lines_other[i][1] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "every_word_no = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word_no[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word_no:\n",
    "        every_word_no[sorted_other_words[i][0]] = every_word_no[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word_no[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word_no = sorted(every_word_no.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Count the number of German words in Anki audio sentences\n",
    "\n",
    "with open('German Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "nor_set = [lines[i][1] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "with open('German Sentences.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines_other  = list(reader)\n",
    "\n",
    "nor_set_other = [lines_other[i][1] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('mary', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "every_word_en = {}\n",
    "\n",
    "for i in every_word_no:\n",
    "    if i not in every_word:\n",
    "        every_word_en[i] = every_word_no[i]\n",
    "\n",
    "print(len(every_word_en), '\\n')\n",
    "sorted_en_words = sorted(every_word_en.items(), key = lambda x: x[1], reverse = True)\n",
    "for i in range(len(sorted_en_words)): print(sorted_en_words[i][0])\n",
    "#left off earth's, advice, taxi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
