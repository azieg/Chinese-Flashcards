{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading audio from tatoeba\n",
    "# Clean CSV sentences/translations file\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(duplicates):\n",
    "    '''We don't want duplicate cards, so removes them with this function'''\n",
    "    clean_tags = list()              # Array that stores tags without duplicates\n",
    "    for tag in duplicates:           # Cycle through each tag\n",
    "        if tag not in clean_tags:    # If a duplicate is found, it is not added to new array\n",
    "            clean_tags.append(tag)   # Add unique tags to array\n",
    "    return clean_tags\n",
    "\n",
    "def remove_sentences(lines):\n",
    "    seen  = set()\n",
    "    block = [row for row in lines if row[0] not in seen and not seen.add(row[0])]\n",
    "    return block\n",
    "\n",
    "with open('Dutch tabbed.csv', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "tags = [lines[i][0] for i in range(len(lines))]                         # Get audio tag numbers from lines\n",
    "tags = remove_tags(tags)                                                # Call remove duplicates function\n",
    "\n",
    "# Populate a URL array where each URL contains a unique tag from the CSV file\n",
    "# Each URL links to a different MP3 file that corresponds to the sentences on the list\n",
    "urls = ['https://audio.tatoeba.org/sentences/nld/' + tags[i] + '.mp3' for i in range(len(tags))]\n",
    "\n",
    "for i in range(len(tags)):\n",
    "    r = requests.get(urls[i])\n",
    "    with open('/Users/Alexander/AppData/Roaming/Anki2/User 1/collection.media/' + tags[i] + '.mp3', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    #print(r.status_code)\n",
    "    #print(r.headers['content-type'])\n",
    "    #print(r.encoding)\n",
    "    \n",
    "print(' -- Download Done -- ')\n",
    "\n",
    "lines = remove_sentences(lines)                                 # Check for duplicate tags in lines\n",
    "\n",
    "for i in range(len(lines)): lines[i].pop(0)                     # Remove tags from first column in the CSV file\n",
    "\n",
    "for i in range(len(lines)): lines[i].append('[sound:' + tags[i] + '.mp3]')\n",
    "    \n",
    "with open('Dutch tabbed.csv', 'w', encoding='utf-8-sig') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines)\n",
    "    \n",
    "writeFile.close()\n",
    "\n",
    "print(' -- Finished -- ')\n",
    "\n",
    "## -- Roadmap --#\n",
    "#! open csv\n",
    "#! take first value of each row -> 'tag'\n",
    "#! check for duplicate tags\n",
    "#! remove duplicate tags\n",
    "#! use tag in url\n",
    "#! download audio to correct directory\n",
    "#! remove duplicate rows in csv\n",
    "#! delete tag value in csv\n",
    "#! add name of sound file using tag to end of each row in csv\n",
    "#! close readcsv\n",
    "#! close writecsv\n",
    "## ------------#\n",
    "\n",
    "# template:  url = 'https://audio.tatoeba.org/sentences/nld/378252.mp3'\n",
    "# media loc: C:\\Users\\Alexander\\AppData\\Roaming\\Anki2\\User 1\\collection.media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 2518\n",
      "from 1668 sentences\n",
      "------------\n",
      "other word count: 1416\n",
      "from 323 other sentences\n",
      "------------\n",
      "total word count: 3430\n",
      "from 1991 total sentences\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Count the number of Norwegian words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('Norwegian Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "#print(nor_set[0])\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('word count:', len(sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_words)): print(sorted_words[i][0], sorted_words[i][1])\n",
    "\n",
    "\n",
    "with open('My Norwegian Phrases.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines_other  = list(reader)                                               # Save contents as list 'lines'\n",
    "\n",
    "nor_set_other = [lines_other[i][0] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('other word count:', len(sorted_other_words))\n",
    "print('from', len(nor_set_other), 'other sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_other_words)): print(sorted_other_words[i][0], sorted_other_words[i][1])\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "print('total word count:', len(sorted_every_word))\n",
    "print('from', (len(nor_set) + len(nor_set_other)), 'total sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_every_word)): print(sorted_every_word[i][0], sorted_every_word[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of Chinese characters in Chinese learning Anki file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('SpoonFedChinese.txt', 'r', encoding = 'utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter = '\\t')\n",
    "    lines = list(reader)\n",
    "    \n",
    "readFile.close()\n",
    "\n",
    "cn_set = [lines[i][2] for i in range(len(lines))]\n",
    "\n",
    "all_char = {}\n",
    "\n",
    "for i in range(len(cn_set)):\n",
    "    \n",
    "    cn_set_spl = list(cn_set[i].replace(\" \", \"\").replace('-', '').replace(\".\", \"\"). replace(\"？\", \"\").replace(\"！\", \"\").replace(\"。\", \"\").replace(\"一\", \"\").replace(\"，\", \"\").replace(\"…\", \"\"))\n",
    "    \n",
    "    for j in range(len(cn_set_spl)):\n",
    "        if cn_set_spl[j] in all_char:\n",
    "            all_char[cn_set_spl[j]] = all_char[cn_set_spl[j]] + 1\n",
    "        else:\n",
    "            all_char[cn_set_spl[j]] = 1\n",
    "            \n",
    "sorted_char = sorted(all_char.items(), key = lambda x: x[1], reverse = True)\n",
    "print('Character count:', len(sorted_char))\n",
    "print('from', len(cn_set), \"sentences\")\n",
    "print('-------------------')\n",
    "for i in range(len(sorted_char)): print(sorted_char[i][0], sorted_char[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('ep1.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "n_lines = len(lines)\n",
    "\n",
    "try:\n",
    "    f = open('new_file.txt')\n",
    "except FileNotFoundError:\n",
    "    print('Creating new file')\n",
    "    with open('new_file.txt', 'a') as g:\n",
    "        g.close()\n",
    "finally:\n",
    "    f.close()\n",
    "\n",
    "# Add source tag to a new column\n",
    "with open('new_file.txt', 'w', encoding='utf-8-sig') as writefile:\n",
    "    for i in range(n_lines):\n",
    "        writefile.write('\\t'.join([lines[i][0], lines[i][1], 'NRK SKEK']) + '\\n')\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(n_lines)]\n",
    "\n",
    "nrk_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('/', '').replace(',', '').replace('-', '').replace('15', '').replace('50', '').replace('60', '').replace('400000', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in nrk_words:\n",
    "            nrk_words[nor_low_spl[j]] = nrk_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            nrk_words[nor_low_spl[j]] = 1\n",
    "\n",
    "nrk_sorted_words = sorted(nrk_words.items(), \n",
    "                      key=lambda x: x[1], \n",
    "                      reverse=True)\n",
    "\n",
    "print('Word Count:', len(nrk_sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "\n",
    "print('------------')\n",
    "\n",
    "#for i in range(len(nrk_sorted_words)):\n",
    "#    print(nrk_sorted_words[i][0], nrk_sorted_words[i][1])\n",
    "#if len(all_words) > len(nrk_words):\n",
    "#    for i in range(len(nrk_words)):\n",
    "#        if nrk_words\n",
    "    \n",
    "#else:\n",
    "if 'er' in nrk_words:\n",
    "    print(nrk_words.items())   \n",
    "\n",
    "#new_dict = all_words.union(nrk_words)\n",
    "#sorted_new = sorted(new_dict.items(),\n",
    "#                   key=lambda x: x[1],\n",
    "#                   reverse=True)\n",
    "\n",
    "#print(sorted_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "all_let = {}\n",
    "st = list(st.replace(\" \", \"\").lower().replace(\".\", \"\"))\n",
    "\n",
    "for i in range(len(st)):\n",
    "    if st[i] in all_let:\n",
    "        all_let[st[i]] = all_let[st[i]] + 1\n",
    "    else:\n",
    "        all_let[st[i]] = 1\n",
    "sort_let = sorted(all_let.items(), key = lambda x: x[1], reverse = True)\n",
    "print('Letter count: ', len(sort_let))\n",
    "print('from', len(st), 'letters')\n",
    "print('-------------')\n",
    "for i in range(len(sort_let)): print(sort_let[i][0], sort_let[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Download Complete -- \n"
     ]
    }
   ],
   "source": [
    "# From Futurelearn Frisian Course\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import csv\n",
    "\n",
    "url = 'https://ugc.futurelearn.com/uploads/assets/c7/ad/c7ad019c-918b-4cdb-be3a-b8be63ca9b32.mp3'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "with open('/Users/Alexander/Documents/College/Audio/Harmen.mp3', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "print(' -- Download Complete -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 1663\n",
      "from 1063 sentences\n",
      "------------\n",
      "other word count: 860\n",
      "from 521 other sentences\n",
      "------------\n",
      "total word count: 2054\n",
      "from 1584 total sentences\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Count the number of German words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('German Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines  = list(reader)                                             # Save contents as list 'lines'\n",
    "\n",
    "nor_set = [lines[i][0] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "#print(nor_set[0])\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('word count:', len(sorted_words))\n",
    "print('from', len(nor_set), 'sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_words)): print(sorted_words[i][0], sorted_words[i][1])\n",
    "\n",
    "\n",
    "with open('German Sentences.txt', 'r', encoding='utf-8-sig') as readFile: # Open the CSV file with translations\n",
    "    reader = csv.reader(readFile, delimiter='\\t')                     # Read the file, set delimiter as 'tab'\n",
    "    lines_other  = list(reader)                                               # Save contents as list 'lines'\n",
    "\n",
    "nor_set_other = [lines_other[i][0] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('-', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "print('other word count:', len(sorted_other_words))\n",
    "print('from', len(nor_set_other), 'other sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_other_words)): print(sorted_other_words[i][0], sorted_other_words[i][1])\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "print('total word count:', len(sorted_every_word))\n",
    "print('from', (len(nor_set) + len(nor_set_other)), 'total sentences')\n",
    "print('------------')\n",
    "#for i in range(len(sorted_every_word)): print(sorted_every_word[i][0], sorted_every_word[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939 \n",
      "\n",
      "whales\n",
      "aluminum\n",
      "being\n",
      "venus\n",
      "krill\n",
      "antarctica\n",
      "physicists\n",
      "bauxite\n",
      "mary\n",
      "turn\n",
      "hanne\n",
      "finn\n",
      "distance\n",
      "themselves\n",
      "others\n",
      "number\n",
      "oslo\n",
      "so-called\n",
      "researchers\n",
      "waves\n",
      "don`t\n",
      "kveld\n",
      "morgen\n",
      "om\n",
      "peter\n",
      "bob\n",
      "sausage\n",
      "grete\n",
      "smoking\n",
      "couldn't\n",
      "count\n",
      "lend\n",
      "difference\n",
      "computers\n",
      "within\n",
      "hand\n",
      "single\n",
      "himself\n",
      "disappeared\n",
      "crowd\n",
      "among\n",
      "gotten\n",
      "surface\n",
      "saying\n",
      "reality\n",
      "meters\n",
      "(sg)\n",
      "creatures\n",
      "relativity\n",
      "sustainable\n",
      "infection\n",
      "consumption\n",
      "emissions\n",
      "phosphine\n",
      "forms\n",
      "(<norsk)\n",
      "dag\n",
      "til\n",
      "clothing\n",
      "fridge\n",
      "washing\n",
      "jonas\n",
      "haven't\n",
      "matter\n",
      "content\n",
      "trust\n",
      "ken\n",
      "crops\n",
      "taking\n",
      "failed\n",
      "standing\n",
      "stood\n",
      "effect\n",
      "produce\n",
      "stands\n",
      "system\n",
      "freezing\n",
      "needs\n",
      "calls\n",
      "products\n",
      "depths\n",
      "certain\n",
      "whale\n",
      "higher\n",
      "equator\n",
      "unable\n",
      "gas\n",
      "fatal\n",
      "weeks\n",
      "choice\n",
      "different\n",
      "label\n",
      "world's\n",
      "wildlife\n",
      "wormholes\n",
      "wormhole\n",
      "gravitational\n",
      "material\n",
      "alumina\n",
      "recycling\n",
      "recycled\n",
      "packaging\n",
      "personal\n",
      "pills\n",
      "mention\n",
      "switzerland\n",
      "går\n",
      "uke\n",
      "måned\n",
      "år\n",
      "blå\n",
      "svart\n",
      "grå\n",
      "how's\n",
      "lady\n",
      "fantastic\n",
      "henrik\n",
      "cigarette\n",
      "cooks\n",
      "covers\n",
      "(sets)\n",
      "cupboard\n",
      "slice\n",
      "stored\n",
      "news\n",
      "truth\n",
      "elbows\n",
      "members\n",
      "silent\n",
      "somebody\n",
      "oneway\n",
      "arrested\n",
      "aren't\n",
      "stealing\n",
      "data\n",
      "itself\n",
      "safety\n",
      "traffic\n",
      "mere\n",
      "wearing\n",
      "actress\n",
      "district\n",
      "repaired\n",
      "calling\n",
      "radio\n",
      "typewriter\n",
      "pocket\n",
      "word\n",
      "journey\n",
      "passing\n",
      "jim\n",
      "we've\n",
      "manage\n",
      "bench\n",
      "interlingua\n",
      "glance\n",
      "hasn't\n",
      "uses\n",
      "snake\n",
      "becomes\n",
      "sofa\n",
      "verb\n",
      "allen\n",
      "given\n",
      "humanity\n",
      "teeth\n",
      "telephone\n",
      "suit\n",
      "license\n",
      "sticks\n",
      "wood\n",
      "damage\n",
      "wasn't\n",
      "collect\n",
      "butterfly\n",
      "stand\n",
      "terrible\n",
      "awarded\n",
      "filled\n",
      "buried\n",
      "dishes\n",
      "earthquake\n",
      "roof\n",
      "myself\n",
      "race\n",
      "recommended\n",
      "stomach\n",
      "angry\n",
      "theorem\n",
      "dilemma\n",
      "main\n",
      "works\n",
      "selling\n",
      "drugs\n",
      "socks\n",
      "gives\n",
      "wherever\n",
      "assigned\n",
      "glass\n",
      "issue\n",
      "impudence\n",
      "trouble\n",
      "osaka\n",
      "ordered\n",
      "prison\n",
      "box\n",
      "pair\n",
      "rang\n",
      "birds\n",
      "tall\n",
      "taller\n",
      "cross\n",
      "earth's\n",
      "advice\n",
      "taxi\n",
      "recognized\n",
      "heard\n",
      "pleasant\n",
      "product\n",
      "euclidean\n",
      "therefore\n",
      "regards\n",
      "gorgeous\n",
      "fear\n",
      "snakes\n",
      "countries\n",
      "chopped\n",
      "interested\n",
      "lightning\n",
      "b\n",
      "finding\n",
      "stayed\n",
      "antarctic\n",
      "lay\n",
      "mark\n",
      "warmer\n",
      "rock\n",
      "activities\n",
      "random\n",
      "hunting\n",
      "millions\n",
      "tool\n",
      "international\n",
      "thinking\n",
      "killed\n",
      "transported\n",
      "compared\n",
      "europe\n",
      "facing\n",
      "flexible\n",
      "avoid\n",
      "original\n",
      "comprises\n",
      "loudly\n",
      "lead\n",
      "mammal\n",
      "various\n",
      "freedom\n",
      "respect\n",
      "waste\n",
      "song\n",
      "horses\n",
      "list\n",
      "partially\n",
      "strike\n",
      "tons\n",
      "crew\n",
      "0000\n",
      "hold\n",
      "finish\n",
      "believed\n",
      "natural\n",
      "collection\n",
      "test\n",
      "quantum\n",
      "mechanics\n",
      "familiar\n",
      "dinner\n",
      "lie\n",
      "uncertain\n",
      "marked\n",
      "public\n",
      "sexually\n",
      "quantity\n",
      "corresponding\n",
      "advanced\n",
      "view\n",
      "concerned\n",
      "gathered\n",
      "sensitive\n",
      "forced\n",
      "thousands\n",
      "contains\n",
      "friendship\n",
      "exciting\n",
      "meadow\n",
      "individual\n",
      "purism\n",
      "continents\n",
      "inhospitable\n",
      "seal\n",
      "seek\n",
      "territory\n",
      "ensure\n",
      "feast\n",
      "methods\n",
      "huge\n",
      "amounts\n",
      "venture\n",
      "rise\n",
      "global\n",
      "changes\n",
      "larger\n",
      "thus\n",
      "ground\n",
      "developed\n",
      "jellyfish\n",
      "slaughter\n",
      "decades\n",
      "protecting\n",
      "transformed\n",
      "polar\n",
      "walrus\n",
      "create\n",
      "phenomenon\n",
      "springs\n",
      "dense\n",
      "source\n",
      "stake\n",
      "einstein's\n",
      "carried\n",
      "holes\n",
      "roll\n",
      "detectors\n",
      "ligo\n",
      "calculated\n",
      "extracted\n",
      "possibilities\n",
      "percent\n",
      "experts\n",
      "feared\n",
      "sort\n",
      "manufacturer\n",
      "arrows\n",
      "shows\n",
      "goods\n",
      "districts\n",
      "per\n",
      "inhabitants\n",
      "infected\n",
      "norwegians\n",
      "greater\n",
      "microbes\n",
      "explanation\n",
      "amount\n",
      "lifestyle\n",
      "period\n",
      "unhealthily\n",
      "expression\n",
      "goodbye\n",
      "hi\n",
      "(very\n",
      "much)\n",
      "sverre\n",
      "pleased\n",
      "27\n",
      "(singular)\n",
      "(neut)\n",
      "(sub)\n",
      "(plural)\n",
      "(obj)\n",
      "(<english)\n",
      "en\n",
      "ett\n",
      "(number)\n",
      "tre\n",
      "fem\n",
      "seks\n",
      "sju\n",
      "åtte\n",
      "ni\n",
      "ti\n",
      "elleve\n",
      "tolv\n",
      "tretten\n",
      "fjorten\n",
      "femten\n",
      "seksten\n",
      "sytten\n",
      "atten\n",
      "nitten\n",
      "tjue\n",
      "tjueen\n",
      "tjueett\n",
      "tjueto\n",
      "tretti\n",
      "førti\n",
      "femti\n",
      "seksti\n",
      "sytti\n",
      "åtti\n",
      "nitti\n",
      "hundre\n",
      "tusen\n",
      "milliard\n",
      "første\n",
      "annen\n",
      "andre\n",
      "tredje\n",
      "fjerde\n",
      "femte\n",
      "sjette\n",
      "sjuende\n",
      "åttende\n",
      "niende\n",
      "tiende\n",
      "ellevte\n",
      "tolvte\n",
      "trettende\n",
      "fjortende\n",
      "femtende\n",
      "sekstende\n",
      "syttende\n",
      "attende\n",
      "nittende\n",
      "tjuende\n",
      "tjueførste\n",
      "tjueandre\n",
      "trettiende\n",
      "førtiende\n",
      "femtiende\n",
      "sekstiende\n",
      "syttiende\n",
      "åttiende\n",
      "nittiende\n",
      "hundrede\n",
      "tusende\n",
      "mandag\n",
      "tirsdag\n",
      "onsdag\n",
      "torsdag\n",
      "fredag\n",
      "lørdag\n",
      "søndag\n",
      "ettermiddag\n",
      "natt\n",
      "morges\n",
      "tidlig\n",
      "formiddag\n",
      "overmorgen\n",
      "forgårs\n",
      "neste\n",
      "helg\n",
      "daglig\n",
      "ukentlig\n",
      "januar\n",
      "februar\n",
      "mai\n",
      "juni\n",
      "juli\n",
      "oktober\n",
      "desember\n",
      "forrige\n",
      "månedlig\n",
      "(n)\n",
      "fjor\n",
      "årlig\n",
      "vinter\n",
      "vår\n",
      "(<season)\n",
      "sommer\n",
      "høst\n",
      "vinteren\n",
      "våren\n",
      "sommeren\n",
      "høsten\n",
      "nord\n",
      "øst\n",
      "vest\n",
      "nordøst\n",
      "nordvest\n",
      "høyre\n",
      "venstre\n",
      "rett\n",
      "fram\n",
      "oransje\n",
      "rosa\n",
      "lilla\n",
      "blått\n",
      "gul\n",
      "gult\n",
      "gule\n",
      "rød\n",
      "rødt\n",
      "røde\n",
      "svarte\n",
      "brun\n",
      "brunt\n",
      "brune\n",
      "grått\n",
      "hvit\n",
      "hvitt\n",
      "hvite\n",
      "grønn\n",
      "grønt\n",
      "grønne\n",
      "humidmuggy\n",
      "temperature\n",
      "fog\n",
      "lifting\n",
      "(cold\n",
      "ice)\n",
      "bjorn\n",
      "hannah\n",
      "billy\n",
      "maria\n",
      "halvor\n",
      "malin\n",
      "seelook\n",
      "pee\n",
      "pythagoras\n",
      "leaving\n",
      "lick\n",
      "(regularly)\n",
      "mushrooms\n",
      "berries\n",
      "chanterelles\n",
      "strawberries\n",
      "store\n",
      "drives\n",
      "shitfuckdamn\n",
      "cleaning\n",
      "cleaned\n",
      "(do\n",
      "for)\n",
      "breadroll\n",
      "buys\n",
      "smokes\n",
      "flowerpot\n",
      "ow\n",
      "23\n",
      "(for\n",
      "room)\n",
      "rooms\n",
      "dish\n",
      "boils\n",
      "cuts\n",
      "(old)\n",
      "slices\n",
      "jam\n",
      "salami\n",
      "kjersti\n",
      "bolivia\n",
      "bergen\n",
      "52\n",
      "kroner\n",
      "everyday\n",
      "2\n",
      "guitarist\n",
      "fluent\n",
      "saih\n",
      "celebrates\n",
      "th\n",
      "wondered\n",
      "sam\n",
      "god\n",
      "musical\n",
      "happens\n",
      "quit\n",
      "ueno\n",
      "mistake\n",
      "astronaut\n",
      "resting\n",
      "mentioned\n",
      "kings\n",
      "arms\n",
      "dick\n",
      "tickets\n",
      "natto\n",
      "awful\n",
      "endless\n",
      "debate\n",
      "connection\n",
      "robbery\n",
      "fits\n",
      "perfectly\n",
      "victory\n",
      "defeat\n",
      "solely\n",
      "size\n",
      "army\n",
      "unless\n",
      "accuse\n",
      "mysterious\n",
      "college\n",
      "proved\n",
      "bookstores\n",
      "politeness\n",
      "persian\n",
      "sleeping\n",
      "education\n",
      "deeply\n",
      "ireland\n",
      "lace\n",
      "branch\n",
      "humanities\n",
      "patiently\n",
      "digging\n",
      "facts\n",
      "critic\n",
      "concise\n",
      "warned\n",
      "provide\n",
      "tents\n",
      "cola\n",
      "railroad\n",
      "interrupted\n",
      "beings\n",
      "basic\n",
      "desires:\n",
      "realize\n",
      "prosperity\n",
      "spite\n",
      "snowstorm\n",
      "sassy\n",
      "resolution\n",
      "paragraph\n",
      "vague\n",
      "master\n",
      "soccer\n",
      "rude\n",
      "curt\n",
      "reply\n",
      "macintosh\n",
      "puts\n",
      "competition\n",
      "shame\n",
      "opinions\n",
      "differ\n",
      "bore\n",
      "grudge\n",
      "responsibility\n",
      "fixing\n",
      "adopted\n",
      "alternative\n",
      "method\n",
      "dropped\n",
      "bookstore\n",
      "hill\n",
      "frying\n",
      "irresponsible\n",
      "johnny\n",
      "brother's\n",
      "audience\n",
      "comedian's\n",
      "wit\n",
      "salary\n",
      "enables\n",
      "comfort\n",
      "ozone\n",
      "banish\n",
      "anxiety\n",
      "nod\n",
      "deceives\n",
      "appearance\n",
      "senior\n",
      "sightseeing\n",
      "tours\n",
      "respectable\n",
      "dozed\n",
      "efforts\n",
      "vain\n",
      "pupils\n",
      "confess\n",
      "deepest\n",
      "fledgling\n",
      "hit\n",
      "inventor\n",
      "parcel\n",
      "passengers\n",
      "ink\n",
      "sunglasses\n",
      "borrowing\n",
      "lighter\n",
      "enter\n",
      "postponing\n",
      "scotland\n",
      "dwarf\n",
      "tossing\n",
      "olympian\n",
      "worrying\n",
      "witnessed\n",
      "murder\n",
      "thanked\n",
      "subscribe\n",
      "newsletter\n",
      "irrational\n",
      "duty\n",
      "society\n",
      "recorder\n",
      "stimulated\n",
      "mastering\n",
      "patience\n",
      "ashamed\n",
      "son's\n",
      "laziness\n",
      "seat\n",
      "prisoner\n",
      "faucet\n",
      "softener\n",
      "trial\n",
      "telling\n",
      "usual\n",
      "stranger\n",
      "examination\n",
      "contrast\n",
      "desperate\n",
      "inflation\n",
      "months'\n",
      "rent\n",
      "deposit\n",
      "discussing\n",
      "hotel\n",
      "gym\n",
      "pool\n",
      "ships\n",
      "harbor\n",
      "dave\n",
      "mutual\n",
      "misunderstanding\n",
      "southeast\n",
      "dared\n",
      "missing\n",
      "citizen\n",
      "meets\n",
      "minimum\n",
      "cultural\n",
      "standards\n",
      "shouldn't\n",
      "there'll\n",
      "whistle\n",
      "blew\n",
      "boat\n",
      "pull\n",
      "died\n",
      "braces\n",
      "ourselves\n",
      "keeping\n",
      "accustomed\n",
      "caused\n",
      "chaos\n",
      "fingers\n",
      "neighbours\n",
      "abnormal\n",
      "unemployed\n",
      "communication\n",
      "thirtyone\n",
      "buries\n",
      "favourite\n",
      "traveled\n",
      "popular\n",
      "amongst\n",
      "korean\n",
      "everybody\n",
      "row\n",
      "deadend\n",
      "vanilla\n",
      "creams\n",
      "photograph\n",
      "reminded\n",
      "countryside\n",
      "hardboiled\n",
      "brazil\n",
      "feels\n",
      "woken\n",
      "nightmare\n",
      "iceland\n",
      "belonged\n",
      "denmark\n",
      "unsolvable\n",
      "crime\n",
      "unwell\n",
      "quick\n",
      "popcorn\n",
      "ii\n",
      "brush\n",
      "disturb\n",
      "border\n",
      "passport\n",
      "printing\n",
      "diabetes\n",
      "globally\n",
      "using\n",
      "nick\n",
      "owes\n",
      "12\n",
      "volumes\n",
      "ambulance\n",
      "electrician\n",
      "wires\n",
      "champagne\n",
      "she'd\n",
      "saving\n",
      "occasion\n",
      "john\n",
      "engaged\n",
      "grocery\n",
      "fields\n",
      "(be\n",
      "fulfilled)\n",
      "skis\n",
      "chopsticks\n",
      "lasted\n",
      "volunteer\n",
      "stumbled\n",
      "stairs\n",
      "separate\n",
      "refuse\n",
      "thoroughly\n",
      "wide\n",
      "hips\n",
      "steady\n",
      "burglars\n",
      "promised\n",
      "cheaply\n",
      "scissors\n",
      "served\n",
      "coconut\n",
      "shells\n",
      "caught\n",
      "glimpse\n",
      "instantly\n",
      "denied\n",
      "brought\n",
      "burning\n",
      "line\n",
      "prizes\n",
      "contest\n",
      "joy\n",
      "hatchet\n",
      "acts\n",
      "kick\n",
      "momentary\n",
      "pause\n",
      "cycled\n",
      "speed\n",
      "documents\n",
      "appears\n",
      "climbing\n",
      "village\n",
      "heart\n",
      "presents\n",
      "boyfriend\n",
      "jail\n",
      "homes\n",
      "mumbled\n",
      "faithful\n",
      "laid\n",
      "damaged\n",
      "oxygen\n",
      "hydrogen\n",
      "astonished\n",
      "sudden\n",
      "mood\n",
      "speech\n",
      "save\n",
      "function\n",
      "lipschitz\n",
      "continuous\n",
      "sew\n",
      "woke\n",
      "abandoned\n",
      "(left\n",
      "alone)\n",
      "(see)\n",
      "uninformed\n",
      "misinformed\n",
      "sisters\n",
      "blonde\n",
      "(took)\n",
      "proofreading\n",
      "regrettable\n",
      "relatively\n",
      "occurence\n",
      "fatigue\n",
      "central\n",
      "nervous\n",
      "pedestrian\n",
      "university's\n",
      "followed\n",
      "scared\n",
      "snored\n",
      "gun\n",
      "heavy\n",
      "beijing\n",
      "page\n",
      "textbook\n",
      "flew\n",
      "applies\n",
      "degree\n",
      "wholly\n",
      "sore\n",
      "submerge\n",
      "ocean's\n",
      "cycle\n",
      "(skillful)\n",
      "shut\n",
      "roads\n",
      "rome\n",
      "borrows\n",
      "mrs\n",
      "jones\n",
      "bombs\n",
      "jordan\n",
      "trivial\n",
      "reader\n",
      "finite\n",
      "note\n",
      "maximum\n",
      "parliamentary\n",
      "republic\n",
      "burst\n",
      "laughing\n",
      "marry\n",
      "adherents\n",
      "religions\n",
      "belarus\n",
      "diligently\n",
      "photos\n",
      "idealism\n",
      "regardless\n",
      "intelligence\n",
      "physical\n",
      "lands\n",
      "profession\n",
      "occupation\n",
      "waited\n",
      "unsuccessfully\n",
      "closely\n",
      "related\n",
      "price\n",
      "varies\n",
      "overanxious\n",
      "concerts\n",
      "eternity\n",
      "length\n",
      "jane's\n",
      "anesthesia\n",
      "mahjong\n",
      "simultaneousinterpreter\n",
      "stepped\n",
      "carefully\n",
      "accelerator\n",
      "fishing\n",
      "meanwhile\n",
      "frustrated\n",
      "task\n",
      "repairing\n",
      "microphone\n",
      "(any)\n",
      "atleast\n",
      "vivid\n",
      "imagination\n",
      "remotest\n",
      "salty\n",
      "particular\n",
      "customs\n",
      "magnesium\n",
      "chemical\n",
      "element\n",
      "employee\n",
      "harder\n",
      "yuri\n",
      "baseball\n",
      "property\n",
      "mike\n",
      "wallet\n",
      "shooting\n",
      "grain\n",
      "beware\n",
      "hook\n",
      "cleared\n",
      "bumped\n",
      "45\n",
      "prior\n",
      "departure\n",
      "poisoned\n",
      "fugu\n",
      "(pufferfish)\n",
      "jane\n",
      "twin\n",
      "strictly\n",
      "tomato\n",
      "fruit\n",
      "channel\n",
      "separates\n",
      "upside\n",
      "tea\n",
      "competed\n",
      "neighbour\n",
      "renovated\n",
      "questionable\n",
      "force\n",
      "remind\n",
      "cape\n",
      "stopped\n",
      "temple\n",
      "built\n",
      "convenient\n",
      "6\n",
      "pm\n",
      "p\n",
      "ladder\n",
      "solid\n",
      "tim\n",
      "seeking\n",
      "employment\n",
      "saturated\n",
      "guards\n",
      "midnight\n",
      "poems\n",
      "below\n",
      "league\n",
      "opened\n",
      "confuse\n",
      "desire\n",
      "nancy\n",
      "lonely\n",
      "shirts\n",
      "carry\n",
      "load\n",
      "4\n",
      "elevator\n",
      "intenionally\n",
      "gradually\n",
      "tadpoles\n",
      "tale\n",
      "disappears\n",
      "begins\n",
      "legs\n",
      "predict\n",
      "jeans\n",
      "girls\n",
      "concept\n",
      "website\n",
      "misses\n",
      "approve\n",
      "essential\n",
      "greatful\n",
      "ring\n",
      "perished\n",
      "blaze\n",
      "gossip\n",
      "deceived\n",
      "deceive\n",
      "emits\n",
      "fragrance\n",
      "massacre\n",
      "prisoners\n",
      "suits\n",
      "pigeons\n",
      "magnetic\n",
      "people's\n",
      "peculiar\n",
      "apparatus\n",
      "produces\n",
      "ache\n",
      "whoever\n",
      "pet\n",
      "cemetery\n",
      "dragon\n",
      "imaginary\n",
      "regarded\n",
      "preparing\n",
      "voyage\n",
      "chose\n",
      "argued\n",
      "easiest\n",
      "iron\n",
      "owe\n",
      "yen\n",
      "constituents\n",
      "organized\n",
      "logic\n",
      "trading\n",
      "shy\n",
      "compare\n",
      "blackboard\n",
      "temples\n",
      "picnic\n",
      "accompanied\n",
      "advantage\n",
      "proceed\n",
      "smith\n",
      "totally\n",
      "engrossed\n",
      "talked\n",
      "barking\n",
      "chickens\n",
      "hatch\n",
      "skin\n",
      "shot\")\n",
      "enemies\n",
      "owns\n",
      "shakespeare\n",
      "greatest\n",
      "dramatist\n",
      "marks\n",
      "realized\n",
      "[magazine]\n",
      "published\n",
      "farm\n",
      "colorado\n",
      "cradle\n",
      "grave\n",
      "captain\n",
      "abandon\n",
      "zoo\n",
      "spies\n",
      "agitate\n",
      "walks\n",
      "rope\n",
      "complicated\n",
      "harvest\n",
      "wheat\n",
      "desk\n",
      "judy\n",
      "pickpocket\n",
      "fulfilled\n",
      "leaned\n",
      "slightly\n",
      "blame\n",
      "doctors\n",
      "(manage)\n",
      "earns\n",
      "paintings\n",
      "freshwater\n",
      "protest\n",
      "students'\n",
      "telephoned\n",
      "frank\n",
      "honesty\n",
      "virtue\n",
      "ability\n",
      "satisfy\n",
      "hunger\n",
      "whenever\n",
      "saved\n",
      "acquainted\n",
      "mayor\n",
      "absent\n",
      "doubtful\n",
      "bicycle\n",
      "orbit\n",
      "sirius\n",
      "elliptical\n",
      "seller\n",
      "balloon\n",
      "geometry\n",
      "equipped\n",
      "multicore\n",
      "processors\n",
      "based\n",
      "von\n",
      "neumann\n",
      "architecture\n",
      "scale\n",
      "observe\n",
      "mechanical\n",
      "effects\n",
      "classical\n",
      "equations\n",
      "matrix\n",
      "understood\n",
      "flooded\n",
      "region\n",
      "melody\n",
      "hospitalized\n",
      "poet\n",
      "spy\n",
      "worthwhile\n",
      "nearest\n",
      "guide\n",
      "aegis\n",
      "collision\n",
      "averted\n",
      "position\n",
      "paint\n",
      "season\n",
      "experiment\n",
      "failure\n",
      "songs\n",
      "dissolves\n",
      "truck\n",
      "swung\n",
      "hakone\n",
      "translated\n",
      "illness\n",
      "sleeplessness\n",
      "threefourths\n",
      "utilized\n",
      "donna\n",
      "silver\n",
      "spoon\n",
      "shower\n",
      "stores\n",
      "sundays\n",
      "(gatherings)\n",
      "(socialize)\n",
      "physics\n",
      "engine\n",
      "plenty\n",
      "secretary\n",
      "achievement\n",
      "bunch\n",
      "wolf\n",
      "sheep's\n",
      "regularly\n",
      "grapefruits\n",
      "influenza\n",
      "workers\n",
      "transmitted\n",
      "detailed\n",
      "supporting\n",
      "stroll\n",
      "conquered\n",
      "cast\n",
      "pretends\n",
      "difficulties\n",
      "compressing\n",
      "software\n",
      "err\n",
      "divine\n",
      "criminals\n",
      "addicted\n",
      "(beat\n",
      "struck)\n",
      "eye\n",
      "equivalent\n",
      "mind\n",
      "democracy\n",
      "citizens\n",
      "equal\n",
      "rights\n",
      "slight\n",
      "badly\n",
      "caterpillar\n",
      "lovely\n",
      "picasso\n",
      "91\n",
      "governed\n",
      "school's\n",
      "require\n",
      "uniforms\n",
      "fed\n",
      "talks\n",
      "knitting\n",
      "trembled\n",
      "crossed\n",
      "caramelise\n",
      "earned\n",
      "hell\n",
      "rested\n",
      "shade\n",
      "admitted\n",
      "stole\n",
      "swiss\n",
      "remained\n",
      "performance\n",
      "commendable\n",
      "unemployment\n",
      "rate\n",
      "5%\n",
      "latest\n",
      "netherlands\n",
      "hobby\n",
      "toys\n",
      "finland\n",
      "hide\n",
      "pains\n",
      "hitler\n",
      "led\n",
      "lemon\n",
      "almonds\n",
      "peeling\n",
      "celery\n",
      "peel\n",
      "finely\n",
      "chop\n",
      "horseradish\n",
      "whip\n",
      "eggwhites\n",
      "stiff\n",
      "logged\n",
      "anybody\n",
      "interpreted\n",
      "derive\n",
      "latin\n",
      "colleagues\n",
      "brian\n",
      "lipstick\n",
      "kate\n",
      "fought\n",
      "bravely\n",
      "pale\n",
      "discuss\n",
      "healthy\n",
      "vitamin\n",
      "excitement\n",
      "shorter\n",
      "grown\n",
      "supply\n",
      "lately\n",
      "windowpane\n",
      "bedtime\n",
      "accused\n",
      "obey\n",
      "positive\n",
      "attitude\n",
      "(approximately)\n",
      "switch\n",
      "notice\n",
      "pearls\n",
      "genuine\n",
      "artificial\n",
      "envious\n",
      "pass\n",
      "delayed\n",
      "illegal\n",
      "copy\n",
      "author's\n",
      "permission\n",
      "disappointed\n",
      "staring\n",
      "prepared\n",
      "worst\n",
      "ruined\n",
      "childlike\n",
      "charming\n",
      "feelings\n",
      "handful\n",
      "peanuts\n",
      "pays\n",
      "children's\n",
      "behavior\n",
      "fair\n",
      "grades\n",
      "behaved\n",
      "strangely\n",
      "earn\n",
      "roses\n",
      "bloom\n",
      "trace\n",
      "cat's\n",
      "teaching\n",
      "personally\n",
      "giving\n",
      "deathbed\n",
      "calculators\n",
      "british\n",
      "schoolchildren\n",
      "eraser\n",
      "leaning\n",
      "pisa\n",
      "satisfactory\n",
      "booklet\n",
      "principles\n",
      "slavery\n",
      "average\n",
      "day's\n",
      "seemed\n",
      "assumed\n",
      "topics\n",
      "smiled\n",
      "realities\n",
      "tasted\n",
      "allow\n",
      "stars\n",
      "truths\n",
      "gravity\n",
      "astronomer\n",
      "destroyed\n",
      "bridges\n",
      "prefereably\n",
      "rushing\n",
      "incomprehensbily\n",
      "dumb\n",
      "ten-eleven\n",
      "sixties\n",
      "lifelike\n",
      "stretched\n",
      "touch\n",
      "remembered\n",
      "major\n",
      "events\n",
      "recall\n",
      "smooth\n",
      "silk\n",
      "birthmark\n",
      "neck\n",
      "earlobe\n",
      "crying\n",
      "managed\n",
      "naoko\n",
      "purists\n",
      "ideology\n",
      "()\n",
      "langauge\n",
      "overwhelming\n",
      "vulnerable\n",
      "lush\n",
      "surprises\n",
      "african\n",
      "plains\n",
      "vast\n",
      "wilderness\n",
      "explore\n",
      "remote\n",
      "precious\n",
      "species\n",
      "diversity\n",
      "mainland\n",
      "dependent\n",
      "surrounds\n",
      "weddell\n",
      "(for)\n",
      "trapped\n",
      "shields\n",
      "blizzards\n",
      "rage\n",
      "raging\n",
      "shelter\n",
      "hardy\n",
      "restless\n",
      "investigated\n",
      "holding\n",
      "struggle\n",
      "consumes\n",
      "loses\n",
      "males\n",
      "opportunity\n",
      "harem\n",
      "centimeter\n",
      "thick\n",
      "layer\n",
      "protects\n",
      "blows\n",
      "opponent\n",
      "retains\n",
      "power\n",
      "forces\n",
      "intruder\n",
      "access\n",
      "teeming\n",
      "powerful\n",
      "currents\n",
      "whirl\n",
      "nutrients\n",
      "richer\n",
      "shoals\n",
      "estimates\n",
      "400000\n",
      "swallow\n",
      "humpback\n",
      "bubbles\n",
      "vertically\n",
      "gaping\n",
      "swallows\n",
      "abundance\n",
      "level\n",
      "immediate\n",
      "threat\n",
      "coldest\n",
      "significant\n",
      "impact\n",
      "loving\n",
      "touches\n",
      "beaks\n",
      "strengthens\n",
      "bonds\n",
      "tender\n",
      "moments\n",
      "windswept\n",
      "continent\n",
      "ensured\n",
      "storms\n",
      "frequent\n",
      "nest\n",
      "brutal\n",
      "claimed\n",
      "victims\n",
      "succumbed\n",
      "environment\n",
      "rely\n",
      "agility\n",
      "killer\n",
      "mohawk\n",
      "feathers\n",
      "measurements\n",
      "glaciers\n",
      "calve\n",
      "shore\n",
      "brash\n",
      "everywhere\n",
      "floes\n",
      "giant\n",
      "penguins\n",
      "exhausted\n",
      "fasten\n",
      "grip\n",
      "transforming\n",
      "hides\n",
      "stable\n",
      "bustling\n",
      "diverse\n",
      "extra\n",
      "begun\n",
      "anyway\n",
      "challenging\n",
      "fertilize\n",
      "offspring\n",
      "bell\n",
      "meter\n",
      "diameter\n",
      "anemones\n",
      "crank\n",
      "monster\n",
      "devour\n",
      "ruthlessly\n",
      "wiped\n",
      "slaughtered\n",
      "lard\n",
      "bodies\n",
      "oil\n",
      "margarine\n",
      "soap\n",
      "ruthless\n",
      "trusting\n",
      "swam\n",
      "boats\n",
      "reduced\n",
      "35\n",
      "mature\n",
      "female\n",
      "lived\n",
      "extensive\n",
      "60-ton\n",
      "giants\n",
      "cautious\n",
      "protected\n",
      "recovered\n",
      "restoration\n",
      "waters\n",
      "significance\n",
      "beyond\n",
      "continent's\n",
      "elephant\n",
      "witness\n",
      "bouffe\n",
      "filmed\n",
      "teaming\n",
      "leopard\n",
      "anytime\n",
      "anywhere\n",
      "extends\n",
      "arctic\n",
      "(polar)\n",
      "circle\n",
      "melts\n",
      "collections\n",
      "mammals\n",
      "chaotic\n",
      "miles\n",
      "threatens\n",
      "inflict\n",
      "harm\n",
      "narrow\n",
      "beaches\n",
      "steep\n",
      "cliffs\n",
      "walruses\n",
      "choose\n",
      "reached\n",
      "themself\n",
      "encounters\n",
      "refuge\n",
      "scare\n",
      "carcasses\n",
      "formation\n",
      "panic\n",
      "occurs\n",
      "heat\n",
      "pushes\n",
      "boiling\n",
      "mud\n",
      "steam\n",
      "dangerously\n",
      "radius\n",
      "mile\n",
      "grass\n",
      "step\n",
      "(can\n",
      "be)\n",
      "caracasses\n",
      "scalded\n",
      "death\n",
      "loner\n",
      "alpha\n",
      "male\n",
      "leads\n",
      "herd\n",
      "edgeoutskirts\n",
      "search\n",
      "reach\n",
      "himalayas\n",
      "iran\n",
      "hotest\n",
      "deserts\n",
      "mouthful\n",
      "counts\n",
      "moving\n",
      "annual\n",
      "monsoon\n",
      "forth\n",
      "rainforests\n",
      "develop\n",
      "termites\n",
      "acquire\n",
      "adventurous\n",
      "branches\n",
      "here's\n",
      "reward:\n",
      "mango\n",
      "juicy\n",
      "sound\n",
      "carries\n",
      "jungle\n",
      "lap\n",
      "maintain\n",
      "answered\n",
      "fenced\n",
      "protection\n",
      "extent\n",
      "destruction\n",
      "sadtragic\n",
      "fishermen\n",
      "income\n",
      "value\n",
      "(speed)\n",
      "skater\n",
      "strava\n",
      "theoretically\n",
      "contain\n",
      "shortcuts\n",
      "universes\n",
      "exotic\n",
      "objects\n",
      "creates\n",
      "tunnel\n",
      "derived\n",
      "knowns\n",
      "vanderbilt\n",
      "determine\n",
      "calculations\n",
      "sun's\n",
      "mass\n",
      "falls\n",
      "runsempties\n",
      "releases\n",
      "deform\n",
      "measured\n",
      "virgo\n",
      "respectively\n",
      "italy\n",
      "smaller\n",
      "swallowed\n",
      "(one)\n",
      "increasingascending\n",
      "frequency\n",
      "passes\n",
      "(a)\n",
      "decisiveconclusive\n",
      "throughout\n",
      "celebrated\n",
      "triumphs\n",
      "(clock)\n",
      "tremoring\n",
      "tremor\n",
      "swallowing\n",
      "albert\n",
      "predicted\n",
      "event\n",
      "enthusiasm\n",
      "time's\n",
      "passage\n",
      "objective\n",
      "perceive\n",
      "raw\n",
      "clay-like\n",
      "soil\n",
      "belt\n",
      "mines\n",
      "oxide\n",
      "refining\n",
      "thereafter\n",
      "clay\n",
      "washed\n",
      "crushing\n",
      "separated\n",
      "lye\n",
      "lime\n",
      "warms\n",
      "filters\n",
      "remainingresidual\n",
      "dries\n",
      "powder\n",
      "metalworks\n",
      "refined\n",
      "converted\n",
      "liquid\n",
      "drain\n",
      "cells\n",
      "extrusion\n",
      "technique\n",
      "limitless\n",
      "design\n",
      "offers\n",
      "countless\n",
      "application\n",
      "metal\n",
      "melted\n",
      "(tire)\n",
      "rims\n",
      "scrap\n",
      "requires\n",
      "persent\n",
      "efficiency\n",
      "aluminum's\n",
      "properties\n",
      "process\n",
      "concerning\n",
      "smarter\n",
      "flows\n",
      "(of\n",
      "river)\n",
      "tray\n",
      "yard\n",
      "flappingfluttering\n",
      "cricket\n",
      "pillar\n",
      "[in\n",
      "thermometer]\n",
      "rises\n",
      "temporarily\n",
      "outdoor\n",
      "toilets\n",
      "correctly\n",
      "sorted\n",
      "eco-labeling\n",
      "misleading\n",
      "according\n",
      "anja\n",
      "consumers\n",
      "tricked\n",
      "environmental\n",
      "informs\n",
      "nrk\n",
      "removed\n",
      "hinders\n",
      "machines\n",
      "sorting\n",
      "recognizing\n",
      "aware\n",
      "replacing\n",
      "21\n",
      "eco-labeled\n",
      "european\n",
      "symbol\n",
      "\"green\n",
      "point\"\n",
      "tag\n",
      "reminder\n",
      "waste-sort\n",
      "durable\n",
      "moist\n",
      "receipt\n",
      "approved\n",
      "return\n",
      "categorized\n",
      "\"red\"\n",
      "ranking\n",
      "infections\n",
      "registered\n",
      "past\n",
      "council\n",
      "newly\n",
      "municipality\n",
      "contexts\n",
      "social\n",
      "groups\n",
      "weddings\n",
      "confirmations\n",
      "parties\n",
      "300000\n",
      "rush\n",
      "significantly\n",
      "growth\n",
      "sacred\n",
      "mantra\n",
      "25\n",
      "beaten\n",
      "luxembourg\n",
      "traveling\n",
      "people:\n",
      "grobetrotters\n",
      "board\n",
      "australia\n",
      "garment\n",
      "synthetic\n",
      "freely\n",
      "consume\n",
      "imported\n",
      "damand\n",
      "delivers\n",
      "8\n",
      "annually\n",
      "policy\n",
      "addresses\n",
      "tools\n",
      "measure\n",
      "inhabitants'\n",
      "footprints\n",
      "possibly\n",
      "detailedelaborate\n",
      "affair\n",
      "orientate\n",
      "swarmcrowd\n",
      "choices\n",
      "old-fashioned\n",
      "composesamounts\n",
      "actual\n",
      "services\n",
      "feeling\n",
      "happiness\n",
      "killing\n",
      "either\n",
      "renewed\n",
      "autumn\n",
      "wardrobe\n",
      "fretex\n",
      "unpleasent\n",
      "footprint\n",
      "municipality's\n",
      "kingdom\n",
      "astronomers\n",
      "speculated\n",
      "inhabitable\n",
      "discovery\n",
      "journals\n",
      "astrobiology\n",
      "emphasize\n",
      "results\n",
      "consideredregarded\n",
      "surprisingastronishing\n",
      "scientist\n",
      "sara\n",
      "searched\n",
      "elsewhere\n",
      "solar\n",
      "ice-decked\n",
      "moons\n",
      "europa\n",
      "enceladus\n",
      "neighbor\n",
      "interest\n",
      "extreme\n",
      "cover\n",
      "acidic\n",
      "indicates\n",
      "continuously\n",
      "produced\n",
      "industially\n",
      "thrive\n",
      "oxygen-free\n",
      "environments\n",
      "molecules\n",
      "model\n",
      "considered\n",
      "sunlight\n",
      "minerals\n",
      "blown\n",
      "volcanoes\n",
      "sources\n",
      "observed\n",
      "conclusion\n",
      "\"anomalous\n",
      "unknown\n",
      "chemistry\"\n",
      "\"this\n",
      "signs\n",
      "extraterrestrial\n",
      "seen\"\n",
      "alan\n",
      "warns\n",
      "tempting\n",
      "organisms\n",
      "excluderule-out\n",
      "non-biological\n",
      "explanations\n",
      "ou\n",
      "evenings\n",
      "disconnect\n",
      "'gamers'\n",
      "splay\n",
      "excess\n",
      "also\"\n",
      "survey\n",
      "[info]\n",
      "exercised\n",
      "jorunn\n",
      "irregularly\n",
      "unfortunate\n",
      "slips\n",
      "recover\n",
      "corona\n",
      "anxious\n",
      "training\n",
      "centers\n",
      "football\n",
      "match\n",
      "forests\n",
      "\"great\n",
      "riches\n",
      "delightsglory\"\n",
      "\"there\n",
      "forests\"\n",
      "terence's\n",
      "comedy\n",
      "\"phormio\"\n"
     ]
    }
   ],
   "source": [
    "# Count the number of Norwegian words in Anki audio sentences\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('Norwegian Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "nor_set = [lines[i][1] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('-', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "with open('My Norwegian Phrases.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines_other  = list(reader)\n",
    "\n",
    "nor_set_other = [lines_other[i][1] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "every_word_no = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word_no[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word_no:\n",
    "        every_word_no[sorted_other_words[i][0]] = every_word_no[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word_no[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word_no = sorted(every_word_no.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Count the number of German words in Anki audio sentences\n",
    "\n",
    "with open('German Sentences with Audio.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines  = list(reader)\n",
    "\n",
    "nor_set = [lines[i][1] for i in range(len(lines))]\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "for i in range(len(nor_set)):\n",
    "    \n",
    "    nor_low_spl = nor_set[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl)):\n",
    "        if nor_low_spl[j] in all_words:\n",
    "            all_words[nor_low_spl[j]] = all_words[nor_low_spl[j]] + 1\n",
    "        else:\n",
    "            all_words[nor_low_spl[j]] = 1\n",
    "\n",
    "sorted_words = sorted(all_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "with open('German Sentences.txt', 'r', encoding='utf-8-sig') as readFile:\n",
    "    reader = csv.reader(readFile, delimiter='\\t')\n",
    "    lines_other  = list(reader)\n",
    "\n",
    "nor_set_other = [lines_other[i][1] for i in range(len(lines_other))]\n",
    "\n",
    "other_words = {}\n",
    "\n",
    "for i in range(len(nor_set_other)):\n",
    "    \n",
    "    nor_low_spl_oth = nor_set_other[i].replace('.', '').replace('?', '').replace('!', '').replace('(<--norsk)', '').replace('/', '').replace('(pronoun)', '').replace('(<--english)', '').replace(',', '').replace('maria', '').replace('malin', '').replace('halvor', '').replace('billy', '').replace('hannah', '').replace('bob', '').replace('bjorn', '').replace('pisa', '').replace('jim', '').replace('mary', '').replace('10', '').replace('15', '').replace('19', '').replace('20', '').replace('50', '').replace('70', '').replace('einstein', '').replace('albert', '').lower().split()\n",
    "    \n",
    "    for j in range(len(nor_low_spl_oth)):\n",
    "        if nor_low_spl_oth[j] in other_words:\n",
    "            other_words[nor_low_spl_oth[j]] = other_words[nor_low_spl_oth[j]] + 1\n",
    "        else:\n",
    "            other_words[nor_low_spl_oth[j]] = 1\n",
    "            \n",
    "sorted_other_words = sorted(other_words.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "every_word = {}\n",
    "\n",
    "for i in range(len(all_words)): every_word[sorted_words[i][0]] = all_words[sorted_words[i][0]]\n",
    "\n",
    "for i in range(len(other_words)):\n",
    "    if sorted_other_words[i][0] in every_word:\n",
    "        every_word[sorted_other_words[i][0]] = every_word[sorted_other_words[i][0]] + sorted_other_words[i][1]\n",
    "    else:\n",
    "        every_word[sorted_other_words[i][0]] = sorted_other_words[i][1]\n",
    "        \n",
    "sorted_every_word = sorted(every_word.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "every_word_en = {}\n",
    "\n",
    "for i in every_word_no:\n",
    "    if i not in every_word:\n",
    "        every_word_en[i] = every_word_no[i]\n",
    "\n",
    "print(len(every_word_en), '\\n')\n",
    "sorted_en_words = sorted(every_word_en.items(), key = lambda x: x[1], reverse = True)\n",
    "for i in range(len(sorted_en_words)): print(sorted_en_words[i][0])\n",
    "#left off earth's, advice, taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
